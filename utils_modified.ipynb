{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "utils_modified.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPq7NyHi2qCQ+n8NHtIYdad",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dharris50/Test/blob/master/utils_modified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZwwbYGxZfdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "temp = tf.zeros([4, 32, 32, 3])  # Or tf.zeros\n",
        "preprocess_input(temp)\n",
        "# IMAGE_SIZE = (224, 224)\n",
        "# TRAIN_SIZE = 50000\n",
        "# VALIDATION_SIZE = 10000\n",
        "# BATCH_SIZE_PER_GPU = 32\n",
        "# global_batch_size = (BATCH_SIZE_PER_GPU * 1)\n",
        "# NUM_CLASSES = 10\n",
        "# TEST = 100\n",
        "# EPOCHS = 64 if == 1 else 2\n",
        "# NUM_PROC = 2\n",
        "\n",
        "def flip(x: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Flip augmentation\n",
        "    Args:\n",
        "        x: Image to flip\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "    x = tf.image.random_flip_left_right(x)\n",
        "    x = tf.image.random_flip_up_down(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def color(x: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Color augmentation\n",
        "    Args:\n",
        "        x: Image\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "    x = tf.image.random_hue(x, 0.08)\n",
        "    x = tf.image.random_saturation(x, 0.6, 1.6)\n",
        "    x = tf.image.random_brightness(x, 0.05)\n",
        "    x = tf.image.random_contrast(x, 0.7, 1.3)\n",
        "    return x\n",
        "\n",
        "def rotate(x: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Rotation augmentation\n",
        "    Args:\n",
        "        x: Image\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "\n",
        "    return tf.image.rot90(x, tf.random.uniform(shape=[], minval=0, maxval=4, dtype=tf.int32))\n",
        "\n",
        "def zoom(x: tf.Tensor) -> tf.Tensor:\n",
        "    \"\"\"Zoom augmentation\n",
        "    Args:\n",
        "        x: Image\n",
        "    Returns:\n",
        "        Augmented image\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate 20 crop settings, ranging from a 1% to 20% crop.\n",
        "    scales = list(np.arange(0.8, 1.0, 0.01))\n",
        "    boxes = np.zeros((len(scales), 4))\n",
        "\n",
        "    for i, scale in enumerate(scales):\n",
        "        x1 = y1 = 0.5 - (0.5 * scale)\n",
        "        x2 = y2 = 0.5 + (0.5 * scale)\n",
        "        boxes[i] = [x1, y1, x2, y2]\n",
        "\n",
        "    # def random_crop(img):\n",
        "    def random_crop(img, IMAGE_SIZE):\n",
        "        # Create different crops for an image\n",
        "        crops = tf.image.crop_and_resize([img], boxes=boxes, box_indices=np.zeros(len(scales)), crop_size=IMAGE_SIZE)\n",
        "        # Return a random crop\n",
        "        return crops[tf.random.uniform(shape=[], minval=0, maxval=len(scales), dtype=tf.int32)]\n",
        "\n",
        "\n",
        "    choice = tf.random.uniform(())\n",
        "\n",
        "    # Only apply cropping 50% of the time\n",
        "    return tf.cond(choice < 0.5, lambda: x, lambda: random_crop(x))\n",
        "\n",
        "def normalize(input_image):\n",
        "  return preprocess_input(input_image)\n",
        "\n",
        "@tf.function\n",
        "# def load_image_train(datapoint):\n",
        "def load_image_train(datapoint, IMAGE_SIZE, NUM_CLASSES):\n",
        "  input_image, label = tf.image.resize(datapoint[\"image\"], IMAGE_SIZE), datapoint['label']\n",
        "  # if tf.random.uniform(()) > 0.5:\n",
        "  #   input_image = tf.image.flip_left_right(input_image)\n",
        "  augmentations = [flip, color, zoom, rotate]\n",
        "  for f in augmentations:\n",
        "    input_image = tf.cond(tf.random.uniform(()) > 0.75, lambda: f(input_image), lambda: input_image)\n",
        "\n",
        "  #input_image = preprocess_input(input_image)\n",
        "  input_image = normalize(input_image)\n",
        "\n",
        "  return input_image, tf.one_hot(label, depth=NUM_CLASSES)\n",
        "\n",
        "@tf.function\n",
        "# def load_image_test(datapoint):\n",
        "def load_image_test(datapoint, IMAGE_SIZE, NUM_CLASSES):\n",
        "  input_image, label = tf.image.resize(datapoint[\"image\"], IMAGE_SIZE), datapoint['label']\n",
        "  #input_image = preprocess_input(input_image)\n",
        "\n",
        "  input_image = normalize(input_image)\n",
        "\n",
        "  return input_image, tf.one_hot(label, depth=NUM_CLASSES)\n",
        "\n",
        "class LayerBatch(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, input_model, dataset):\n",
        "        self.input_model = input_model\n",
        "        self.dataset = dataset.__iter__()\n",
        "\n",
        "    # def __len__(self):\n",
        "    def __len__(self, TRAIN_SIZE, global_batch_size):\n",
        "      return math.ceil(TRAIN_SIZE // global_batch_size )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X, y = self.input_model(next(self.dataset))\n",
        "        return X, y\n",
        "\n",
        "class LayerBatchSynth(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, input_model, dataset):\n",
        "        self.input_model = input_model\n",
        "        self.dataset = dataset.__iter__()\n",
        "\n",
        "    # def __len__(self):    \n",
        "    def __len__(self, global_batch_size):\n",
        "        return math.ceil(4224 // global_batch_size )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X, y = self.input_model(next(self.dataset))\n",
        "        return X, y\n",
        "\n",
        "import math\n",
        "class LayerTest(tf.keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, input_model, dataset):\n",
        "        self.input_model = input_model\n",
        "        self.dataset = dataset.__iter__()\n",
        "\n",
        "    # def __len__(self):\n",
        "    def __len__(self, VALIDATION_SIZE, global_batch_size):\n",
        "        return math.ceil(VALIDATION_SIZE // global_batch_size )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X, y = self.input_model(next(self.dataset))\n",
        "        return X, y\n",
        "\n",
        "def add_layers(inputs, filters, layers=2):\n",
        "    print(inputs.get_shape())\n",
        "    X = tf.keras.layers.SeparableConv2D(name=f'sep_conv_{build_replacement.counter}', filters=filters,\n",
        "                                        kernel_size= (3,3),\n",
        "                                        padding='Same')(inputs)\n",
        "    #X = tf.keras.layers.BatchNormalization(name=f'batch_norm_{build_replacement.counter}')(X)\n",
        "    X = tf.keras.layers.ReLU(name=f'relu_{build_replacement.counter}')(X)\n",
        "\n",
        "    build_replacement.counter += 1\n",
        "\n",
        "    for i in range(1, layers):\n",
        "        X = tf.keras.layers.SeparableConv2D(name=f'sep_conv_{build_replacement.counter}', filters=filters,\n",
        "                                            kernel_size=(3,3),\n",
        "                                            padding='Same')(X)\n",
        "        #X = tf.keras.layers.BatchNormalization(name=f'batch_norm_{build_replacement.counter}')(X)\n",
        "        X = tf.keras.layers.ReLU(name=f'relu_{build_replacement.counter}')(X)\n",
        "        build_replacement.counter += 1\n",
        "\n",
        "    return X\n",
        "\n",
        "def build_replacement(get_output, layers=2):\n",
        "    inputs = tf.keras.Input(shape=get_output.output[0].shape[1::])\n",
        "\n",
        "    X = add_layers(inputs, get_output.output[1].shape[-1], layers)\n",
        "    replacement_layers = tf.keras.Model(inputs=inputs, outputs=X)\n",
        "    return replacement_layers\n",
        "\n",
        "build_replacement.counter = 0\n",
        "\n",
        "def replac(inp, filters):\n",
        "\n",
        "    return add_layers(inp, filters,layers=2)\n",
        "\n",
        "def make_list(X):\n",
        "    if isinstance(X, list):\n",
        "        return X\n",
        "    return [X]\n",
        "\n",
        "def list_no_list(X):\n",
        "    if len(X) == 1:\n",
        "        return X[0]\n",
        "    return X\n",
        "\n",
        "def replace_layer(model, replace_layer_subname, replacement_fn,\n",
        "**kwargs):\n",
        "    \"\"\"\n",
        "    args:\n",
        "        model :: keras.models.Model instance\n",
        "        replace_layer_subname :: str -- if str in layer name, replace it\n",
        "        replacement_fn :: fn to call to replace all instances\n",
        "            > fn output must produce shape as the replaced layers input\n",
        "    returns:\n",
        "        new model with replaced layers\n",
        "    quick examples:\n",
        "        want to just remove all layers with 'batch_norm' in the name:\n",
        "            > new_model = replace_layer(model, 'batch_norm', lambda **kwargs : (lambda u:u))\n",
        "        want to replace all Conv1D(N, m, padding='same') with an LSTM (lets say all have 'conv1d' in name)\n",
        "            > new_model = replace_layer(model, 'conv1d', lambda layer, **kwargs: LSTM(units=layer.filters, return_sequences=True)\n",
        "    \"\"\"\n",
        "    model_inputs = []\n",
        "    model_outputs = []\n",
        "    tsr_dict = {}\n",
        "\n",
        "    model_output_names = [out.name for out in make_list(model.output)]\n",
        "\n",
        "    for i, layer in enumerate(model.layers):\n",
        "        ### Loop if layer is used multiple times\n",
        "        for j in range(len(layer._inbound_nodes)):\n",
        "\n",
        "            ### check layer inp/outp\n",
        "            inpt_names = [inp.name for inp in make_list(layer.get_input_at(j))]\n",
        "            outp_names = [out.name for out in make_list(layer.get_output_at(j))]\n",
        "\n",
        "            ### setup model inputs\n",
        "            if 'input' in layer.name:\n",
        "                for inpt_tsr in make_list(layer.get_output_at(j)):\n",
        "                    model_inputs.append(inpt_tsr)\n",
        "                    tsr_dict[inpt_tsr.name] = inpt_tsr\n",
        "                continue\n",
        "\n",
        "            ### setup layer inputs\n",
        "            # I added the exception model_3_3/Identity:0 I think the problem is that is the input layer\n",
        "            inpt = list_no_list([tsr_dict[name]  for name in inpt_names])\n",
        "\n",
        "            ### remake layer\n",
        "            if layer.name in replace_layer_subname:\n",
        "              if \"relu\" in layer.name or 'bn' in layer.name:\n",
        "                print('deleting ' + layer.name)\n",
        "                x = inpt\n",
        "              else:\n",
        "                print('replacing '+layer.name)\n",
        "                x = replacement_fn(inpt)\n",
        "            else:\n",
        "                x = layer(inpt)\n",
        "\n",
        "            ### reinstantialize outputs into dict\n",
        "            for name, out_tsr in zip(outp_names, make_list(x)):\n",
        "\n",
        "                ### check if is an output\n",
        "                if name in model_output_names:\n",
        "                    model_outputs.append(out_tsr)\n",
        "                tsr_dict[name] = out_tsr\n",
        "\n",
        "    return tf.keras.models.Model(model_inputs, model_outputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nNyiNUXhXx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}